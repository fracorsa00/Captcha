{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, '/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import captcha_setting\n",
    "import my_dataset\n",
    "from captcha_cnn_model import CNN, Generator\n",
    "from torchvision.utils import save_image\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load GAN net.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:155: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:230: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6926\n",
      "0936\n",
      "6494\n",
      "0094\n",
      "4903\n",
      "4313\n",
      "4789\n",
      "7382\n",
      "4200\n",
      "1244\n",
      "2009\n",
      "2413\n",
      "4062\n",
      "4262\n",
      "7869\n",
      "7759\n",
      "6700\n",
      "6738\n",
      "4060\n",
      "6108\n",
      "0790\n",
      "1627\n",
      "4002\n",
      "9147\n",
      "9729\n",
      "7909\n",
      "6098\n",
      "6793\n",
      "4070\n",
      "3151\n",
      "6200\n",
      "6211\n",
      "4877\n",
      "6870\n",
      "7992\n",
      "6823\n",
      "2828\n",
      "2323\n",
      "8642\n",
      "5692\n",
      "4099\n",
      "1139\n",
      "7729\n",
      "6022\n",
      "3079\n",
      "5079\n",
      "0000\n",
      "7178\n",
      "4799\n",
      "0953\n",
      "6000\n",
      "0187\n",
      "4966\n",
      "0201\n",
      "2099\n",
      "2432\n",
      "3809\n",
      "3342\n",
      "4476\n",
      "9308\n",
      "4640\n",
      "0141\n",
      "5486\n",
      "5834\n",
      "6002\n",
      "0132\n",
      "8069\n",
      "7189\n",
      "4709\n",
      "4008\n",
      "7000\n",
      "5146\n",
      "4072\n",
      "5852\n",
      "2777\n",
      "2955\n",
      "6099\n",
      "0822\n",
      "0790\n",
      "4941\n",
      "0708\n",
      "8503\n",
      "9760\n",
      "5538\n",
      "8032\n",
      "5482\n",
      "4077\n",
      "0770\n",
      "0660\n",
      "6661\n",
      "6066\n",
      "6400\n",
      "9772\n",
      "5052\n",
      "4608\n",
      "5838\n",
      "3090\n",
      "6680\n",
      "5770\n",
      "0307\n",
      "4890\n",
      "5999\n",
      "8280\n",
      "0281\n",
      "9598\n",
      "9597\n",
      "4080\n",
      "4131\n",
      "7009\n",
      "5466\n",
      "6976\n",
      "5866\n",
      "4920\n",
      "0921\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-e52895fec99f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;31m#     plt.imshow(imgs[0][0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;31m#     plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e52895fec99f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mimage_root\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_image_file_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mimage_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m160\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2659\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2661\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2663\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(1, '/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char')\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import captcha_setting\n",
    "import my_dataset\n",
    "from captcha_cnn_model import CNN, Generator\n",
    "from torchvision.utils import save_image\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import copy\n",
    "import operator\n",
    "import torch.nn as nn\n",
    "import captcha_setting\n",
    "from matplotlib import cm\n",
    "class testdataset(Dataset):\n",
    "\n",
    "    def __init__(self, folder, transform=None):\n",
    "        self.train_image_file_paths = [os.path.join(folder, image_file) for image_file in os.listdir(folder)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_image_file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_root = self.train_image_file_paths[idx]\n",
    "        image_name = image_root.split(os.path.sep)[-1]\n",
    "        image = Image.open(image_root)\n",
    "        image = image.resize((160,60), Image.ANTIALIAS)\n",
    "        label = image_name\n",
    "        if('_' in image_name):\n",
    "            label = image_name.split('_')[0]\n",
    "        else:\n",
    "            label = image_name.split('.')[0]\n",
    "            \n",
    "        #label = ohe.encode(image_name.split('_')[0]) # 为了方便，在生成图片的时候，图片文件的命名格式 \"4个数字或者数字_时间戳.PNG\", 4个字母或者即是图片的验证码的值，字母大写,同时对该值做 one-hot 处理\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            #label = self.transform(label)\n",
    "        #label = ohe.encode(image_name.split('_')[0])\n",
    "        return image, label\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ColorJitter(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "def get_loader():\n",
    "    img_path = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_data/\"\n",
    "    img_path2 = \"/home/ning_a/Desktop/CAPTCHA/base_GAN/train/\"\n",
    "    img_path3 = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/mania_data/\"\n",
    "    dataset = testdataset(img_path, transform=transform)\n",
    "    return DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear((captcha_setting.IMAGE_WIDTH//8)*(captcha_setting.IMAGE_HEIGHT//8)*64, 1024),\n",
    "            nn.Dropout(0.1),  # drop 50% of the neuron\n",
    "            nn.ReLU())\n",
    "        self.rfc = nn.Sequential(\n",
    "            nn.Linear(1024, 256),#captcha_setting.MAX_CAPTCHA*captcha_setting.ALL_CHAR_SET_LEN),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.rfc2 = nn.Sequential(\n",
    "            nn.Linear(256, captcha_setting.MAX_CAPTCHA*captcha_setting.ALL_CHAR_SET_LEN),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        #print(out.shape)\n",
    "        out = self.rfc(out)\n",
    "        out = self.rfc2(out)\n",
    "        #out = out.view(out.size(0), -1)\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn = CNN()\n",
    "cnn.eval()\n",
    "cnn.load_state_dict(torch.load('model_digit.pkl'))\n",
    "cnn.to(device)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.ColorJitter(),\n",
    "    transforms.Grayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "dataloader = get_loader()\n",
    "\n",
    "generator = Generator()\n",
    "generator.load_state_dict(torch.load('/home/ning_a/Desktop/CAPTCHA/base_solver/base_solver_char/7800.pkl'))\n",
    "generator.eval()\n",
    "print(\"load GAN net.\")\n",
    "\n",
    "img_path = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_data/\"\n",
    "img_path1 = \"/home/ning_a/Desktop/CAPTCHA/dark_web_captcha/rescator_me/\"\n",
    "img_path2 = \"/home/ning_a/Desktop/CAPTCHA/base_GAN/train/\"\n",
    "\n",
    "img = cv.imread(img_path+\"1627.png\")\n",
    "\n",
    "dim = (160, 60)\n",
    "#img = cv.resize(img, dim, interpolation=cv.INTER_CUBIC)\n",
    "#img = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n",
    "# plt.imshow(img)\n",
    "# plt.show()\n",
    "# img.shape\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# img = torch.tensor(img)\n",
    "# img = img.float()\n",
    "# #print(img.type())\n",
    "# new_img = generator(img).data.cpu().numpy()\n",
    "# plt.imshow(new_img[0][0])\n",
    "# plt.show()\n",
    "# #print(img)\n",
    "label_target = \"\"\n",
    "correct = 0\n",
    "total = 0\n",
    "for i, (imgs, label) in enumerate(dataloader):\n",
    "#     plt.imshow(imgs[0][0])\n",
    "#     plt.show()\n",
    "    total += 1\n",
    "#     if(i<10):\n",
    "#         continue\n",
    "#     print(label)\n",
    "    label_target = label\n",
    "    imgs = torch.tensor(imgs).float()\n",
    "    new_img = generator(imgs)\n",
    "    new_img2 = new_img.data.cpu().numpy()\n",
    "    target_img = new_img2[0][0]\n",
    "    target_img = target_img*255\n",
    "    cv.imwrite( \"temp.jpg\",target_img) \n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    img = cv.imread('temp.jpg')\n",
    "#     plt.imshow(img)\n",
    "#     plt.show()\n",
    "    threshold = 5  \n",
    "    img = np.array(img)\n",
    "    n_img = np.zeros((img.shape[0],img.shape[1]))\n",
    "    img_aft = cv.normalize(img, n_img, 0,255,cv.NORM_MINMAX)\n",
    "#     plt.imshow(img_aft)\n",
    "#     plt.show()\n",
    "    gray = cv.cvtColor(img_aft,cv.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv.threshold(gray,0,255,cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n",
    "    ret, thresh_reverse = cv.threshold(gray,0,255,cv.THRESH_OTSU)\n",
    "    #>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
    "    im2,contours,hierarchy = cv.findContours(thresh,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)\n",
    "    filter_containor = []\n",
    "    temp_img = copy.deepcopy(img)\n",
    "    cur_contours = []\n",
    "    #print(len(contours))\n",
    "    for i in contours:\n",
    "        #print(i)\n",
    "        x, y, w, h = cv.boundingRect(i)   \n",
    "        cur_contours.append([x, y, w, h])\n",
    "        #break\n",
    "    contours = sorted(cur_contours, key=operator.itemgetter(0))\n",
    "    #print(len(contours))\n",
    "    for i in range(0,len(contours)):  \n",
    "        x = contours[i][0]\n",
    "        y = contours[i][1]\n",
    "        w = contours[i][2] \n",
    "        h = contours[i][3]\n",
    "        #= cv.boundingRect(contours[i])   \n",
    "        newimage=thresh_reverse[y:y+h,x:x+w] # 先用y确定高，再用x确定宽\n",
    "        nrootdir=(\"cut_image/\")\n",
    "        if h<5 and w<5:\n",
    "            continue\n",
    "        color = [255, 255, 255]\n",
    "        top, bottom, left, right = [1]*4\n",
    "\n",
    "        newimage = cv.copyMakeBorder(newimage, top, bottom, left, right, cv.BORDER_CONSTANT, value=color)\n",
    "        #newimage = \n",
    "        newimage = cv.resize(newimage,(30, 60), interpolation = cv.INTER_CUBIC)\n",
    "        #filter_containor.append(newimage)\n",
    "\n",
    "        cv.rectangle(temp_img, (x,y), (x+w,y+h), (153,153,0), 1)\n",
    "        if not os.path.isdir(nrootdir):\n",
    "            os.makedirs(nrootdir)\n",
    "        cv.imwrite( nrootdir+str(i)+\".jpg\",newimage)\n",
    "        cv.imwrite( \"temp.jpg\",newimage) \n",
    "        filter_containor.append(Image.open(\"temp.jpg\"))\n",
    "#         print (x, y, w, h)\n",
    "    #print(filter_containor)\n",
    "#     plt.imshow(temp_img)\n",
    "#     plt.show()\n",
    "    #>>>>>>>>>>>>>>>>>>>>>\n",
    "    label_predicted = \"\"\n",
    "    filter_containor = []\n",
    "    for i in range(4):\n",
    "        cv.imwrite( \"temp.jpg\",img[:,i*40:i*40+40])\n",
    "        filter_containor.append(Image.open(\"temp.jpg\"))\n",
    "    for eachimg in filter_containor:\n",
    "        #print(eachimg)\n",
    "        fix_size = (30, 60)\n",
    "        eachimg = eachimg.resize(fix_size)\n",
    "        image = transform(eachimg).unsqueeze(0)\n",
    "#         plt.imshow(eachimg)\n",
    "#         plt.show()\n",
    "#         print(image.shape)\n",
    "        \n",
    "        image = torch.tensor(image, device=device).float()\n",
    "        image = Variable(image).to(device)\n",
    "        #print(image.shape)\n",
    "        #image, labels =  image.to(device), labels.to(device)\n",
    "        # vimage = generator(image)\n",
    "        predict_label = cnn(image)\n",
    "        #labels = labels.cpu()\n",
    "        predict_label = predict_label.cpu()\n",
    "        _, predicted = torch.max(predict_label, 1)\n",
    "#         print(captcha_setting.ALL_CHAR_SET[predicted])\n",
    "        label_predicted += captcha_setting.ALL_CHAR_SET[predicted]\n",
    "#     print(label_predicted)\n",
    "#     print(label[0])\n",
    "    if(label_predicted==label[0]):\n",
    "        correct += 1\n",
    "#     break\n",
    "print(correct/total)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
